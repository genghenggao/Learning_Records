[TOC]



## 一. 使用单机local模式提交任务

##### 1、在master节点，启动Spark集群

- 进入`/usr/local/spark-2.4.4-bin-hadoop2.7/sbin/`

```shell
[root@master hduser]# cd /usr/local/spark-2.4.4-bin-hadoop2.7/sbin/
```

- 启动Spark集群
  - **注意：上面的命令中有./这个不能少，./的意思是执行当前目录下的start-all.sh脚本。**

